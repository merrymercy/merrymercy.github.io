---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# About
I am a member of technical staff at xAI. I lead the inference team responsible for building efficient and reliable infrastructure to run Grok models.
My expertise includes machine learning systems, large language models, compilers, and distributed systems.

Previously, I completed my Ph.D. at UC Berkeley, where I was advised by Ion Stoica and Joseph E. Gonzalez.
I obtained my B.S. degree from ACM Honored Class, Shanghai Jiao Tong University.
I was honored to receive the Meta PhD Fellowship and the a16z Open Source AI Grant (twice) in recognition of my innovative research and impactful open-source projects.
I also co-founded the non-profit organization [LMSYS.org](https://lmsys.org/) to advance open research on large models.
We have developed open models with <u>millions of downloads</u>, crowdsourced platforms with <u>millions of users</u>, and systems that are <u>orders of magnitude</u> faster.

# Research
- Systems for training and serving large models
   - Projects: [SGLang](https://github.com/sgl-project/sglang/tree/main) (lead), [FastChat](https://github.com/lm-sys/FastChat) (lead), [Alpa](https://github.com/alpa-projects/alpa) (lead), [FlexGen](https://github.com/FMInference/FlexGen), [vLLM](https://github.com/vllm-project/vllm)
   - First-author publications: [NeurIPS 24](https://arxiv.org/abs/2312.07104), [OSDI 22](https://arxiv.org/abs/2201.12023), [OSDI 23](https://arxiv.org/abs/2302.11665), [ICML 21](https://arxiv.org/abs/2104.14129)
   - Other publications: [ICML 23](https://arxiv.org/abs/2303.06865), [SOSP 23](https://arxiv.org/abs/2309.06180), [MLSys 23](https://arxiv.org/abs/2211.05322), [MLSys 24](https://arxiv.org/abs/2311.03285)
- Open large language models, benchmarks, and datasets for large language models
   - Projects: [Vicuna](https://lmsys.org/blog/2023-03-30-vicuna/) (lead), [Chatbot Arena](https://chat.lmsys.org/) (lead), [LMSYS-Chat-1M](https://huggingface.co/datasets/lmsys/lmsys-chat-1m) (lead)
   - First-author publications: [NeurIPS 23](https://arxiv.org/abs/2306.05685), [ICML 24](https://arxiv.org/abs/2403.04132), [ICLR 24](https://arxiv.org/abs/2309.11998), [Preprint 23](https://arxiv.org/abs/2311.04850)
- Deep learning compilers and auto-tuning
   - Projects: [TVM](https://tvm.apache.org/), [Ansor](https://tvm.apache.org/docs/how_to/tune_with_autoscheduler/index.html) (lead)
   - First-author publications: [OSDI 20](https://arxiv.org/abs/2006.06762), [NeurIPS 21](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/a684eceee76fc522773286a895bc8436-Abstract-round1.html)
   - Other publications: [OSDI 18](https://arxiv.org/abs/1802.04799), [NeurIPS 20](https://arxiv.org/pdf/1805.08166.pdf), [ASPLOS 23](https://arxiv.org/abs/2207.04296)

\*(lead) indicates that I lead or co-lead the project.

[More publications](https://lmzheng.net/publications/)
